"""Search orchestration for query generation, execution, and chunk deduplication."""

import asyncio
import logging
from typing import List, Dict, Any
from ai import get_agent
from clients import get_cosmos_client
from core.config import (
    RETRIEVAL_TOP_K_PER_QUERY,
    RETRIEVAL_TIMEOUT_SECONDS
)


class Search:
    """Orchestrates document search: query generation, parallel execution, and deduplication."""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.agent = get_agent()
        self.cosmos_client = get_cosmos_client()

    async def _generate_search_queries(
        self, section_name: str, section_description: str,
        template_description: str, project_description: str
    ) -> List[str]:
        """Generate search queries using AI agent"""
        self.logger.info("Calling search agent")
        queries = await asyncio.wait_for(
            self.agent.plan_retrieval(
                section_name, section_description, template_description, project_description
            ),
            timeout=RETRIEVAL_TIMEOUT_SECONDS / 3
        )

        if not queries:
            raise ValueError("No queries generated by agent")

        self.logger.info(f"[SEARCH] Generated {len(queries)} queries: {queries}")
        return queries

    async def _execute_search_queries(
        self, queries: List[str],
        file_ids: List[str]
    ) -> List[Dict[str, Any]]:
        """Execute all search queries in parallel without concurrency limit"""
        tasks = [self._execute_query(q, file_ids, i) for i, q in enumerate(queries)]
        chunk_results = await asyncio.gather(*tasks, return_exceptions=True)

        all_chunks = []
        for i, result in enumerate(chunk_results):
            if isinstance(result, Exception):
                self.logger.warning(f"[SEARCH] Query {i} failed: {result}")
                continue
            if isinstance(result, list):
                all_chunks.extend(result)

        if not all_chunks:
            raise ValueError("No chunks retrieved from any query")

        return all_chunks

    def _deduplicate_chunks(self, all_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove duplicate chunks based on chunk ID"""
        seen = set()
        unique_chunks = []
        for chunk in all_chunks:
            chunk_id = chunk.get("id")
            if chunk_id and chunk_id not in seen:
                seen.add(chunk_id)
                unique_chunks.append(chunk)

        return unique_chunks

    async def _execute_query(self, query: str,
                             file_ids: List[str], query_index: int = 0) -> List[Dict[str, Any]]:
        """Execute a single search query across specified files."""
        try:
            chunks = await asyncio.wait_for(
                self.cosmos_client.search(
                    query=query,
                    file_ids=file_ids,
                    top_k=RETRIEVAL_TOP_K_PER_QUERY
                ),
                timeout=RETRIEVAL_TIMEOUT_SECONDS / 4
            )

            # Add query information to each chunk
            for chunk in chunks:
                chunk['query_info'] = {
                    'query_text': query,
                    'query_index': query_index
                }

            # No filtering - return all chunks as is
            return chunks
        except asyncio.TimeoutError:
            self.logger.error(f"Timeout processing query: {query}")
            raise ValueError(f"Query timeout: {query}")
        except Exception as e:
            self.logger.error(f"Error processing query '{query}': {e}")
            raise ValueError(f"Query failed: {e}")
